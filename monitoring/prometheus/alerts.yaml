apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: phase-v
data:
  alerts.yaml: |
    groups:
      - name: Phase-V Application Alerts
        interval: 30s
        rules:
          # High error rate alert
          - alert: HighErrorRate
            expr: |
              sum(rate(task_operations_total{status="error"}[5m])) 
              / sum(rate(task_operations_total[5m])) > 0.05
            for: 5m
            labels:
              severity: critical
              service: phase-v
            annotations:
              summary: "High error rate detected"
              description: "Error rate is {{ $value | humanizePercentage }} over the last 5 minutes"

          # Pod restart alert
          - alert: PodRestarting
            expr: |
              changes(kube_pod_container_status_restarts_total{namespace="todo-app"}[1h]) > 3
            for: 5m
            labels:
              severity: warning
              service: phase-v
            annotations:
              summary: "Pod is restarting frequently"
              description: "Pod {{ $labels.pod }} has restarted {{ $value }} times in the last hour"

          # Service down alert
          - alert: ServiceDown
            expr: |
              up{namespace="todo-app", job=~"phase-v-.*"} == 0
            for: 2m
            labels:
              severity: critical
              service: phase-v
            annotations:
              summary: "Service is down"
              description: "Service {{ $labels.job }} has been down for more than 2 minutes"

          # High latency alert
          - alert: HighLatency
            expr: |
              histogram_quantile(0.95, sum(rate(task_operation_duration_seconds_bucket[5m])) by (le, operation)) > 2
            for: 5m
            labels:
              severity: warning
              service: phase-v
            annotations:
              summary: "High latency detected"
              description: "95th percentile latency for {{ $labels.operation }} is {{ $value }}s"

          # Event processing errors
          - alert: EventProcessingErrors
            expr: |
              sum(rate(event_processing_errors_total[5m])) > 0.1
            for: 5m
            labels:
              severity: warning
              service: phase-v-events
            annotations:
              summary: "Event processing errors detected"
              description: "{{ $value }} event processing errors per second"

          # Consumer lag alert
          - alert: HighConsumerLag
            expr: |
              consumer_lag_messages > 1000
            for: 5m
            labels:
              severity: warning
              service: phase-v-events
            annotations:
              summary: "High consumer lag detected"
              description: "Consumer {{ $labels.consumer }} has {{ $value }} messages lag"

          # DLQ messages alert
          - alert: DLQMessages
            expr: |
              sum(rate(dlq_messages_total[5m])) > 0
            for: 5m
            labels:
              severity: warning
              service: phase-v-events
            annotations:
              summary: "Messages being sent to DLQ"
              description: "{{ $value }} messages per second being sent to dead letter queue"

          # Reminder scheduling errors
          - alert: ReminderSchedulingErrors
            expr: |
              sum(rate(reminder_scheduling_errors_total[5m])) > 0.05
            for: 5m
            labels:
              severity: warning
              service: phase-v-reminders
            annotations:
              summary: "Reminder scheduling errors detected"
              description: "{{ $value }} reminder scheduling errors per second"

          # WebSocket connections dropped
          - alert: WebSocketConnectionsDropped
            expr: |
              changes(websocket_connections_active[5m]) < 0
            for: 2m
            labels:
              severity: warning
              service: phase-v-websocket
            annotations:
              summary: "WebSocket connections being dropped"
              description: "WebSocket connections decreased by {{ $value }} in 5 minutes"

      - name: Infrastructure Alerts
        interval: 30s
        rules:
          # High CPU usage
          - alert: HighCPUUsage
            expr: |
              sum(rate(container_cpu_usage_seconds_total{namespace="todo-app"}[5m])) by (pod)
              / sum(kube_pod_container_resource_limits{namespace="todo-app", resource="cpu"}) by (pod) > 0.8
            for: 10m
            labels:
              severity: warning
              service: infrastructure
            annotations:
              summary: "High CPU usage detected"
              description: "Pod {{ $labels.pod }} CPU usage is above 80%"

          # High memory usage
          - alert: HighMemoryUsage
            expr: |
              sum(container_memory_working_set_bytes{namespace="todo-app"}) by (pod)
              / sum(kube_pod_container_resource_limits{namespace="todo-app", resource="memory"}) by (pod) > 0.8
            for: 10m
            labels:
              severity: warning
              service: infrastructure
            annotations:
              summary: "High memory usage detected"
              description: "Pod {{ $labels.pod }} memory usage is above 80%"

          # Disk space low
          - alert: DiskSpaceLow
            expr: |
              (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 20
            for: 10m
            labels:
              severity: warning
              service: infrastructure
            annotations:
              summary: "Low disk space"
              description: "Disk space is below 20% on {{ $labels.instance }}"

          # Node not ready
          - alert: NodeNotReady
            expr: |
              kube_node_status_condition{condition="Ready", status="true"} == 0
            for: 5m
            labels:
              severity: critical
              service: infrastructure
            annotations:
              summary: "Node is not ready"
              description: "Node {{ $labels.node }} is not ready"

      - name: Dapr Alerts
        interval: 30s
        rules:
          # Dapr sidecar not healthy
          - alert: DaprSidecarNotHealthy
            expr: |
              dapr_runtime_component_status{status="healthy"} == 0
            for: 5m
            labels:
              severity: critical
              service: dapr
            annotations:
              summary: "Dapr sidecar not healthy"
              description: "Dapr sidecar for app {{ $labels.app_id }} is not healthy"

          # Dapr component not ready
          - alert: DaprComponentNotReady
            expr: |
              dapr_runtime_component_initialized{initialized="0"} == 1
            for: 5m
            labels:
              severity: warning
              service: dapr
            annotations:
              summary: "Dapr component not initialized"
              description: "Dapr component {{ $labels.component }} is not initialized"

          # Dapr HTTP request failures
          - alert: DaprHTTPRequestFailures
            expr: |
              sum(rate(dapr_runtime_http_response_count{status_code=~"5.."}[5m])) > 0.1
            for: 5m
            labels:
              severity: warning
              service: dapr
            annotations:
              summary: "Dapr HTTP request failures"
              description: "{{ $value }} Dapr HTTP requests failing per second"
